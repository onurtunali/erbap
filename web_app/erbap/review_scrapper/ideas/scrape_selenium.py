"""
DESCRIPTION:
Scraping the newest reviews from a given goodreads book url. Script works as follows:
    1. Get the given url and open with webdriver of selenium.
    2. Sort the reviews by newest.
    3. Parse the returned web page using BeautifulSoup4 to isolate reviews.
    4. Append the reviews to global mutable list object `reviews`.
    5. Move to the next page until none is left.
TODO:
    - Add argument parsing such that script can be run from commandline.
    - Add loggin module to compare files in Data Lake to implement "change data capture" principle.
DEPENDENCIES:
    - selenium==3.11.0
    - beautifulsoup4==4.10.0
    - geckodriver-v0.30.0-linux64
SCARPING ELEMENTS:
    - rating stars `<span class=" staticStars notranslate" title="liked it">`
        - 5: "it was amazing"
        - 4: "really liked it"
        - 3: "liked it"
        - 2: "it was ok"
        - 1: "did not like it"
"""

import time
from hashlib import sha1

from bs4 import BeautifulSoup
from selenium.webdriver import Chrome
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.common.by import By


def get_browser(implicit_wait):
    opts = Options()
    opts.headless = True
    opts.add_argument("--headless")
    opts.add_argument("--no-sandbox")
    opts.add_argument("--disable-dev-shm-usage")

    browser = Chrome("chromedriver", options=opts)
    browser.implicitly_wait(implicit_wait)
    return browser


urls = [
    "https://www.goodreads.com/book/show/6088007-neuromancer",
    # "https://www.goodreads.com/book/show/154091.Mona_Lisa_Overdrive",
]

url_parameters = "?text_only=true"
reviews = []


def get_reviews(reviews, src):
    """
    This function parses the given `src` text string consistinf of HTML tags and outputs cleaned reviews strings.

    Parameters
    ----------
    reviews: Main mutable list containing the reviews regarding the book url points.

    src: String object generated by BeautifulSoup including HTML tags.

    Returns
    -------
    reviews: Main mutable list containing the review tuples (date, review_text, hash) regarding the book url points.
    """
    soup = BeautifulSoup(src, "lxml")
    review_elements = soup.find_all("div", {"class": "friendReviews elementListBrown"})

    for review in review_elements:
        date = review.find_all("a", {"class": "reviewDate createdAt right"})[
            0
        ].text.strip()
        date = date.replace(",", "")
        # date = str(date).encode("utf-8")
        review = review.find_all("div", {"class": "reviewText stacked"})[0].text.strip()
        review = str(review).encode("utf-8")
        reviews.add((date, sha1(review).hexdigest(), review.decode("utf-8")))

    return reviews


def main(urls, reviews):
    review_limit = 10
    for url in urls:
        try:
            if browser:
                browser.quit()
                print("Browser is shut down!")
        except:
            pass

        browser = get_browser(5)
        current_reviews = set()
        page = 0
        url = url + url_parameters
        try_count = 0

        while True:
            try:
                browser.get(url)
                time.sleep(3)
                break
            except:
                print("Waiting for connection")
                time.sleep(3)
                try_count += 1

            if try_count > 5:
                print("Couldn't establish connection")
                break
                return reviews

        """
        This preprocess moves hovers to sort order menu and get the Newest reviews.
        """
        browser.maximize_window()
        action = ActionChains(browser)
        hover = browser.find_element(By.LINK_TEXT, "Sort order")
        action.move_to_element(hover).perform()
        newest = browser.find_element(By.LINK_TEXT, "Newest")
        action.move_to_element(newest).perform()
        newest.click()
        time.sleep(2)

        is_finished = False

        while not is_finished:
            src = browser.page_source
            current_reviews = get_reviews(current_reviews, src)
            page += 1

            try:
                next_page = browser.find_element(By.CLASS_NAME, "next_page")
                browser.execute_script("arguments[0].click();", next_page)

            except Exception as e:
                print(e)
                is_finished = True

            if len(current_reviews) >= review_limit:
                break

            print(
                f"Current reviews: {len(current_reviews)}\nPage number: {page}\nCurrent url:"
            )

        reviews.append(list(current_reviews))
    return reviews


if __name__ == "__main__":
    reviews = main(urls, reviews)
    for review in reviews:
        print(f"Number of reviews: {len(review)}")
